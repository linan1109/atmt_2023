{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, collections\n",
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "SPACE_NORMALIZER = re.compile(\"\\s+\")\n",
    "\n",
    "def line_split(line):\n",
    "    line = SPACE_NORMALIZER.sub(\" \", line)\n",
    "    line = line.strip()\n",
    "    words = line.split()\n",
    "    words = [word + \"Ġ\" for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pair_freqs(splits, word_freqs):\n",
    "    pair_freqs = defaultdict(int)\n",
    "    for word, freq in word_freqs.items():\n",
    "        split = splits[word]\n",
    "        if len(split) == 1:\n",
    "            continue\n",
    "        for i in range(len(split) - 1):\n",
    "            pair = (split[i], split[i + 1])\n",
    "            pair_freqs[pair] += freq\n",
    "    return pair_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pair(a, b, splits, word_freqs):\n",
    "    for word in word_freqs:\n",
    "        split = splits[word]\n",
    "        if len(split) == 1:\n",
    "            continue\n",
    "\n",
    "        i = 0\n",
    "        while i < len(split) - 1:\n",
    "            if split[i] == a and split[i + 1] == b:\n",
    "                split = split[:i] + [a + b] + split[i + 2 :]\n",
    "            else:\n",
    "                i += 1\n",
    "        splits[word] = split\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"BPE is an effective method for segmenting words into subword units, thereby enhancing the model's ability to manage rare or out-of-vocabulary words.\",\n",
    "    \"It is reasonable to expect that adapting BPE will result in a higher BLEU score compared to using words exclusively.\",\n",
    "    \"Additionally, the BPE-dropout can contribute to improved model generalization, as it exposes the model to diverse subword representations and variations. \"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freqs = defaultdict(int)\n",
    "for text in corpus:\n",
    "    words = line_split(text)\n",
    "    for word in words:\n",
    "        word_freqs[word] += 1\n",
    "\n",
    "vocab = defaultdict(int)\n",
    "for word in word_freqs.keys():\n",
    "    for letter in word:\n",
    "        vocab[letter] += word_freqs[word]\n",
    "\n",
    "splits = {word: [c for c in word] for word in word_freqs.keys()}\n",
    "\n",
    "merges = {}\n",
    "while len(vocab) < vocab_size:\n",
    "    pair_freqs = compute_pair_freqs(splits, word_freqs)\n",
    "    best_pair = \"\"\n",
    "    max_freq = None\n",
    "    for pair, freq in pair_freqs.items():\n",
    "        if max_freq is None or max_freq < freq:\n",
    "            best_pair = pair\n",
    "            max_freq = freq\n",
    "    if max_freq is None:\n",
    "        break\n",
    "    splits = merge_pair(*best_pair, splits, word_freqs)\n",
    "    merges[best_pair] = best_pair[0] + best_pair[1]\n",
    "    vocab[best_pair[0] + best_pair[1]] = max_freq\n",
    "\n",
    "vocab = sorted(vocab.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ġ', 62),\n",
       " ('e', 38),\n",
       " ('o', 32),\n",
       " ('t', 31),\n",
       " ('i', 26),\n",
       " ('a', 24),\n",
       " ('r', 24),\n",
       " ('s', 22),\n",
       " ('n', 22),\n",
       " ('d', 17),\n",
       " ('l', 14),\n",
       " ('u', 10),\n",
       " ('eĠ', 10),\n",
       " ('c', 9),\n",
       " ('h', 9),\n",
       " ('m', 8),\n",
       " ('g', 8),\n",
       " ('sĠ', 8),\n",
       " ('or', 8),\n",
       " ('b', 7),\n",
       " ('p', 7),\n",
       " ('ti', 7),\n",
       " ('v', 6),\n",
       " ('w', 6),\n",
       " ('th', 6),\n",
       " ('dĠ', 6),\n",
       " ('to', 6),\n",
       " ('toĠ', 6),\n",
       " ('re', 6),\n",
       " ('tĠ', 6),\n",
       " ('on', 6),\n",
       " ('y', 5),\n",
       " ('an', 5),\n",
       " ('wor', 5),\n",
       " ('B', 4),\n",
       " ('E', 4),\n",
       " ('f', 4),\n",
       " ('en', 4),\n",
       " ('ng', 4),\n",
       " ('ngĠ', 4),\n",
       " ('el', 4),\n",
       " ('tion', 4),\n",
       " ('P', 3),\n",
       " (',', 3),\n",
       " ('-', 3),\n",
       " ('.', 3),\n",
       " ('x', 3),\n",
       " ('BP', 3),\n",
       " ('BPE', 3),\n",
       " ('word', 3),\n",
       " ('su', 3),\n",
       " (',Ġ', 3),\n",
       " ('yĠ', 3),\n",
       " ('theĠ', 3),\n",
       " ('mo', 3),\n",
       " ('mod', 3),\n",
       " ('model', 3),\n",
       " ('ab', 3),\n",
       " ('ar', 3),\n",
       " ('.Ġ', 3),\n",
       " ('ex', 3),\n",
       " ('er', 3),\n",
       " ('ation', 3),\n",
       " ('BPEĠ', 2),\n",
       " ('isĠ', 2),\n",
       " ('anĠ', 2),\n",
       " ('ec', 2),\n",
       " ('orĠ', 2),\n",
       " ('se', 2),\n",
       " ('tingĠ', 2),\n",
       " ('wordsĠ', 2),\n",
       " ('in', 2),\n",
       " ('sub', 2),\n",
       " ('subwor', 2),\n",
       " ('subwordĠ', 2),\n",
       " ('it', 2),\n",
       " ('ingĠ', 2),\n",
       " ('il', 2),\n",
       " ('ou', 2),\n",
       " ('s.Ġ', 2),\n",
       " ('exp', 2),\n",
       " ('mp', 2),\n",
       " ('us', 2),\n",
       " ('iv', 2),\n",
       " ('al', 2),\n",
       " ('ro', 2),\n",
       " ('modelĠ', 2),\n",
       " (\"'\", 1),\n",
       " ('I', 1),\n",
       " ('L', 1),\n",
       " ('U', 1),\n",
       " ('A', 1),\n",
       " ('z', 1),\n",
       " ('ef', 1),\n",
       " ('eff', 1),\n",
       " ('effec', 1),\n",
       " ('effecti', 1),\n",
       " ('effectiv', 1),\n",
       " ('effectiveĠ', 1),\n",
       " ('me', 1),\n",
       " ('meth', 1),\n",
       " ('metho', 1),\n",
       " ('methodĠ', 1),\n",
       " ('forĠ', 1),\n",
       " ('seg', 1),\n",
       " ('segm', 1),\n",
       " ('segmen', 1),\n",
       " ('segmentingĠ', 1),\n",
       " ('intoĠ', 1),\n",
       " ('un', 1),\n",
       " ('unit', 1),\n",
       " ('units', 1),\n",
       " ('units,Ġ', 1),\n",
       " ('the', 1),\n",
       " ('there', 1),\n",
       " ('thereb', 1),\n",
       " ('therebyĠ', 1),\n",
       " ('enh', 1),\n",
       " ('enhan', 1),\n",
       " ('enhanc', 1),\n",
       " ('enhancingĠ', 1),\n",
       " (\"model'\", 1),\n",
       " (\"model'sĠ\", 1),\n",
       " ('abil', 1),\n",
       " ('abilit', 1),\n",
       " ('abilityĠ', 1),\n",
       " ('man', 1),\n",
       " ('mana', 1),\n",
       " ('manag', 1),\n",
       " ('manageĠ', 1),\n",
       " ('rar', 1),\n",
       " ('rareĠ', 1),\n",
       " ('out', 1),\n",
       " ('out-', 1),\n",
       " ('out-o', 1),\n",
       " ('out-of', 1),\n",
       " ('out-of-', 1),\n",
       " ('out-of-v', 1),\n",
       " ('out-of-vo', 1),\n",
       " ('out-of-voc', 1),\n",
       " ('out-of-vocab', 1),\n",
       " ('out-of-vocabu', 1),\n",
       " ('out-of-vocabul', 1),\n",
       " ('out-of-vocabular', 1),\n",
       " ('out-of-vocabularyĠ', 1),\n",
       " ('words.Ġ', 1),\n",
       " ('ItĠ', 1),\n",
       " ('rea', 1),\n",
       " ('reas', 1),\n",
       " ('reason', 1),\n",
       " ('reasonab', 1),\n",
       " ('reasonabl', 1),\n",
       " ('reasonableĠ', 1),\n",
       " ('expec', 1),\n",
       " ('expectĠ', 1),\n",
       " ('tha', 1),\n",
       " ('thatĠ', 1),\n",
       " ('ad', 1),\n",
       " ('ada', 1),\n",
       " ('adap', 1),\n",
       " ('adaptingĠ', 1),\n",
       " ('wil', 1),\n",
       " ('will', 1),\n",
       " ('willĠ', 1),\n",
       " ('resu', 1),\n",
       " ('resul', 1),\n",
       " ('resultĠ', 1),\n",
       " ('inĠ', 1),\n",
       " ('aĠ', 1),\n",
       " ('hi', 1),\n",
       " ('hig', 1),\n",
       " ('high', 1),\n",
       " ('higher', 1),\n",
       " ('higherĠ', 1),\n",
       " ('BL', 1),\n",
       " ('BLE', 1),\n",
       " ('BLEU', 1),\n",
       " ('BLEUĠ', 1),\n",
       " ('sc', 1),\n",
       " ('scor', 1),\n",
       " ('scoreĠ', 1),\n",
       " ('co', 1),\n",
       " ('comp', 1),\n",
       " ('compa', 1),\n",
       " ('compare', 1),\n",
       " ('comparedĠ', 1),\n",
       " ('usingĠ', 1),\n",
       " ('exc', 1),\n",
       " ('excl', 1),\n",
       " ('exclus', 1),\n",
       " ('exclusiv', 1),\n",
       " ('exclusivel', 1),\n",
       " ('exclusively', 1),\n",
       " ('exclusively.Ġ', 1),\n",
       " ('Ad', 1),\n",
       " ('Add', 1),\n",
       " ('Addi', 1),\n",
       " ('Addition', 1),\n",
       " ('Additional', 1),\n",
       " ('Additionall', 1),\n",
       " ('Additionally', 1),\n",
       " ('Additionally,Ġ', 1),\n",
       " ('BPE-', 1),\n",
       " ('BPE-d', 1),\n",
       " ('BPE-dro', 1),\n",
       " ('BPE-drop', 1),\n",
       " ('BPE-dropou', 1),\n",
       " ('BPE-dropoutĠ', 1),\n",
       " ('canĠ', 1),\n",
       " ('con', 1),\n",
       " ('cont', 1),\n",
       " ('contr', 1),\n",
       " ('contri', 1),\n",
       " ('contrib', 1),\n",
       " ('contribu', 1),\n",
       " ('contribut', 1),\n",
       " ('contributeĠ', 1),\n",
       " ('imp', 1),\n",
       " ('impro', 1),\n",
       " ('improv', 1),\n",
       " ('improve', 1),\n",
       " ('improvedĠ', 1),\n",
       " ('gen', 1),\n",
       " ('gener', 1),\n",
       " ('general', 1),\n",
       " ('generali', 1),\n",
       " ('generaliz', 1),\n",
       " ('generalization', 1),\n",
       " ('generalization,Ġ', 1),\n",
       " ('asĠ', 1),\n",
       " ('itĠ', 1),\n",
       " ('expo', 1),\n",
       " ('expose', 1),\n",
       " ('exposesĠ', 1),\n",
       " ('div', 1),\n",
       " ('diver', 1),\n",
       " ('divers', 1),\n",
       " ('diverseĠ', 1),\n",
       " ('rep', 1),\n",
       " ('repre', 1),\n",
       " ('repres', 1),\n",
       " ('represen', 1),\n",
       " ('represent', 1),\n",
       " ('representation', 1),\n",
       " ('representationsĠ', 1),\n",
       " ('andĠ', 1),\n",
       " ('var', 1),\n",
       " ('vari', 1),\n",
       " ('variation', 1),\n",
       " ('variations.Ġ', 1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    words = line_split(text)\n",
    "    splits = [[c for c in word] for word in words]\n",
    "    print(splits)\n",
    "    for pair, merge in merges.items():\n",
    "        for idx, split in enumerate(splits):\n",
    "            i = 0\n",
    "            while i < len(split) - 1:\n",
    "                if split[i] == pair[0] and split[i + 1] == pair[1]:\n",
    "                    if random.random() < dropout:\n",
    "                        i += 1\n",
    "                        continue\n",
    "                    split = split[:i] + [merge] + split[i + 2 :]\n",
    "                else:\n",
    "                    i += 1\n",
    "            splits[idx] = split\n",
    "\n",
    "    return sum(splits, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['B', 'P', 'E', 'Ġ'], ['w', 'i', 'l', 'l', 'Ġ'], ['r', 'e', 's', 'u', 'l', 't', 'Ġ'], ['i', 'n', 'Ġ'], ['a', 'Ġ'], ['h', 'i', 'g', 'h', 'e', 'r', 'Ġ'], ['B', 'L', 'E', 'U', 'Ġ'], ['s', 'c', 'o', 'r', 'e', '.', 'Ġ']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['BPEĠ',\n",
       " 'willĠ',\n",
       " 'resultĠ',\n",
       " 'inĠ',\n",
       " 'aĠ',\n",
       " 'higherĠ',\n",
       " 'BLEUĠ',\n",
       " 'scor',\n",
       " 'e',\n",
       " '.Ġ']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout = 0\n",
    "tokenize(\"BPE will result in a higher BLEU score.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['B', 'P', 'E', 'Ġ'], ['w', 'i', 'l', 'l', 'Ġ'], ['r', 'e', 's', 'u', 'l', 't', 'Ġ'], ['i', 'n', 'Ġ'], ['a', 'Ġ'], ['h', 'i', 'g', 'h', 'e', 'r', 'Ġ'], ['B', 'L', 'E', 'U', 'Ġ'], ['s', 'c', 'o', 'r', 'e', '.', 'Ġ']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['BPEĠ',\n",
       " 'willĠ',\n",
       " 'resultĠ',\n",
       " 'inĠ',\n",
       " 'aĠ',\n",
       " 'higherĠ',\n",
       " 'BLEUĠ',\n",
       " 's',\n",
       " 'c',\n",
       " 'or',\n",
       " 'e',\n",
       " '.Ġ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout = 0.05\n",
    "tokenize(\"BPE will result in a higher BLEU score.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save merges\n",
    "with open(\"merges.txt\", \"w\") as f:\n",
    "    for pair, merge in merges.items():\n",
    "        f.write(f\"{pair[0]} {pair[1]} -> {merge}\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('e', 'Ġ'): 'eĠ',\n",
       " ('s', 'Ġ'): 'sĠ',\n",
       " ('o', 'r'): 'or',\n",
       " ('t', 'i'): 'ti',\n",
       " ('t', 'h'): 'th',\n",
       " ('d', 'Ġ'): 'dĠ',\n",
       " ('t', 'o'): 'to',\n",
       " ('to', 'Ġ'): 'toĠ',\n",
       " ('r', 'e'): 're',\n",
       " ('t', 'Ġ'): 'tĠ',\n",
       " ('o', 'n'): 'on',\n",
       " ('a', 'n'): 'an',\n",
       " ('w', 'or'): 'wor',\n",
       " ('e', 'n'): 'en',\n",
       " ('n', 'g'): 'ng',\n",
       " ('ng', 'Ġ'): 'ngĠ',\n",
       " ('e', 'l'): 'el',\n",
       " ('ti', 'on'): 'tion',\n",
       " ('B', 'P'): 'BP',\n",
       " ('BP', 'E'): 'BPE',\n",
       " ('wor', 'd'): 'word',\n",
       " ('s', 'u'): 'su',\n",
       " (',', 'Ġ'): ',Ġ',\n",
       " ('y', 'Ġ'): 'yĠ',\n",
       " ('th', 'eĠ'): 'theĠ',\n",
       " ('m', 'o'): 'mo',\n",
       " ('mo', 'd'): 'mod',\n",
       " ('mod', 'el'): 'model',\n",
       " ('a', 'b'): 'ab',\n",
       " ('a', 'r'): 'ar',\n",
       " ('.', 'Ġ'): '.Ġ',\n",
       " ('e', 'x'): 'ex',\n",
       " ('e', 'r'): 'er',\n",
       " ('a', 'tion'): 'ation',\n",
       " ('BPE', 'Ġ'): 'BPEĠ',\n",
       " ('i', 'sĠ'): 'isĠ',\n",
       " ('an', 'Ġ'): 'anĠ',\n",
       " ('e', 'c'): 'ec',\n",
       " ('or', 'Ġ'): 'orĠ',\n",
       " ('s', 'e'): 'se',\n",
       " ('ti', 'ngĠ'): 'tingĠ',\n",
       " ('word', 'sĠ'): 'wordsĠ',\n",
       " ('i', 'n'): 'in',\n",
       " ('su', 'b'): 'sub',\n",
       " ('sub', 'wor'): 'subwor',\n",
       " ('subwor', 'dĠ'): 'subwordĠ',\n",
       " ('i', 't'): 'it',\n",
       " ('i', 'ngĠ'): 'ingĠ',\n",
       " ('i', 'l'): 'il',\n",
       " ('o', 'u'): 'ou',\n",
       " ('s', '.Ġ'): 's.Ġ',\n",
       " ('ex', 'p'): 'exp',\n",
       " ('m', 'p'): 'mp',\n",
       " ('u', 's'): 'us',\n",
       " ('i', 'v'): 'iv',\n",
       " ('a', 'l'): 'al',\n",
       " ('r', 'o'): 'ro',\n",
       " ('model', 'Ġ'): 'modelĠ',\n",
       " ('e', 'f'): 'ef',\n",
       " ('ef', 'f'): 'eff',\n",
       " ('eff', 'ec'): 'effec',\n",
       " ('effec', 'ti'): 'effecti',\n",
       " ('effecti', 'v'): 'effectiv',\n",
       " ('effectiv', 'eĠ'): 'effectiveĠ',\n",
       " ('m', 'e'): 'me',\n",
       " ('me', 'th'): 'meth',\n",
       " ('meth', 'o'): 'metho',\n",
       " ('metho', 'dĠ'): 'methodĠ',\n",
       " ('f', 'orĠ'): 'forĠ',\n",
       " ('se', 'g'): 'seg',\n",
       " ('seg', 'm'): 'segm',\n",
       " ('segm', 'en'): 'segmen',\n",
       " ('segmen', 'tingĠ'): 'segmentingĠ',\n",
       " ('in', 'toĠ'): 'intoĠ',\n",
       " ('u', 'n'): 'un',\n",
       " ('un', 'it'): 'unit',\n",
       " ('unit', 's'): 'units',\n",
       " ('units', ',Ġ'): 'units,Ġ',\n",
       " ('th', 'e'): 'the',\n",
       " ('the', 're'): 'there',\n",
       " ('there', 'b'): 'thereb',\n",
       " ('thereb', 'yĠ'): 'therebyĠ',\n",
       " ('en', 'h'): 'enh',\n",
       " ('enh', 'an'): 'enhan',\n",
       " ('enhan', 'c'): 'enhanc',\n",
       " ('enhanc', 'ingĠ'): 'enhancingĠ',\n",
       " ('model', \"'\"): \"model'\",\n",
       " (\"model'\", 'sĠ'): \"model'sĠ\",\n",
       " ('ab', 'il'): 'abil',\n",
       " ('abil', 'it'): 'abilit',\n",
       " ('abilit', 'yĠ'): 'abilityĠ',\n",
       " ('m', 'an'): 'man',\n",
       " ('man', 'a'): 'mana',\n",
       " ('mana', 'g'): 'manag',\n",
       " ('manag', 'eĠ'): 'manageĠ',\n",
       " ('r', 'ar'): 'rar',\n",
       " ('rar', 'eĠ'): 'rareĠ',\n",
       " ('ou', 't'): 'out',\n",
       " ('out', '-'): 'out-',\n",
       " ('out-', 'o'): 'out-o',\n",
       " ('out-o', 'f'): 'out-of',\n",
       " ('out-of', '-'): 'out-of-',\n",
       " ('out-of-', 'v'): 'out-of-v',\n",
       " ('out-of-v', 'o'): 'out-of-vo',\n",
       " ('out-of-vo', 'c'): 'out-of-voc',\n",
       " ('out-of-voc', 'ab'): 'out-of-vocab',\n",
       " ('out-of-vocab', 'u'): 'out-of-vocabu',\n",
       " ('out-of-vocabu', 'l'): 'out-of-vocabul',\n",
       " ('out-of-vocabul', 'ar'): 'out-of-vocabular',\n",
       " ('out-of-vocabular', 'yĠ'): 'out-of-vocabularyĠ',\n",
       " ('word', 's.Ġ'): 'words.Ġ',\n",
       " ('I', 'tĠ'): 'ItĠ',\n",
       " ('re', 'a'): 'rea',\n",
       " ('rea', 's'): 'reas',\n",
       " ('reas', 'on'): 'reason',\n",
       " ('reason', 'ab'): 'reasonab',\n",
       " ('reasonab', 'l'): 'reasonabl',\n",
       " ('reasonabl', 'eĠ'): 'reasonableĠ',\n",
       " ('exp', 'ec'): 'expec',\n",
       " ('expec', 'tĠ'): 'expectĠ',\n",
       " ('th', 'a'): 'tha',\n",
       " ('tha', 'tĠ'): 'thatĠ',\n",
       " ('a', 'd'): 'ad',\n",
       " ('ad', 'a'): 'ada',\n",
       " ('ada', 'p'): 'adap',\n",
       " ('adap', 'tingĠ'): 'adaptingĠ',\n",
       " ('w', 'il'): 'wil',\n",
       " ('wil', 'l'): 'will',\n",
       " ('will', 'Ġ'): 'willĠ',\n",
       " ('re', 'su'): 'resu',\n",
       " ('resu', 'l'): 'resul',\n",
       " ('resul', 'tĠ'): 'resultĠ',\n",
       " ('in', 'Ġ'): 'inĠ',\n",
       " ('a', 'Ġ'): 'aĠ',\n",
       " ('h', 'i'): 'hi',\n",
       " ('hi', 'g'): 'hig',\n",
       " ('hig', 'h'): 'high',\n",
       " ('high', 'er'): 'higher',\n",
       " ('higher', 'Ġ'): 'higherĠ',\n",
       " ('B', 'L'): 'BL',\n",
       " ('BL', 'E'): 'BLE',\n",
       " ('BLE', 'U'): 'BLEU',\n",
       " ('BLEU', 'Ġ'): 'BLEUĠ',\n",
       " ('s', 'c'): 'sc',\n",
       " ('sc', 'or'): 'scor',\n",
       " ('scor', 'eĠ'): 'scoreĠ',\n",
       " ('c', 'o'): 'co',\n",
       " ('co', 'mp'): 'comp',\n",
       " ('comp', 'a'): 'compa',\n",
       " ('compa', 're'): 'compare',\n",
       " ('compare', 'dĠ'): 'comparedĠ',\n",
       " ('us', 'ingĠ'): 'usingĠ',\n",
       " ('ex', 'c'): 'exc',\n",
       " ('exc', 'l'): 'excl',\n",
       " ('excl', 'us'): 'exclus',\n",
       " ('exclus', 'iv'): 'exclusiv',\n",
       " ('exclusiv', 'el'): 'exclusivel',\n",
       " ('exclusivel', 'y'): 'exclusively',\n",
       " ('exclusively', '.Ġ'): 'exclusively.Ġ',\n",
       " ('A', 'd'): 'Ad',\n",
       " ('Ad', 'd'): 'Add',\n",
       " ('Add', 'i'): 'Addi',\n",
       " ('Addi', 'tion'): 'Addition',\n",
       " ('Addition', 'al'): 'Additional',\n",
       " ('Additional', 'l'): 'Additionall',\n",
       " ('Additionall', 'y'): 'Additionally',\n",
       " ('Additionally', ',Ġ'): 'Additionally,Ġ',\n",
       " ('BPE', '-'): 'BPE-',\n",
       " ('BPE-', 'd'): 'BPE-d',\n",
       " ('BPE-d', 'ro'): 'BPE-dro',\n",
       " ('BPE-dro', 'p'): 'BPE-drop',\n",
       " ('BPE-drop', 'ou'): 'BPE-dropou',\n",
       " ('BPE-dropou', 'tĠ'): 'BPE-dropoutĠ',\n",
       " ('c', 'anĠ'): 'canĠ',\n",
       " ('c', 'on'): 'con',\n",
       " ('con', 't'): 'cont',\n",
       " ('cont', 'r'): 'contr',\n",
       " ('contr', 'i'): 'contri',\n",
       " ('contri', 'b'): 'contrib',\n",
       " ('contrib', 'u'): 'contribu',\n",
       " ('contribu', 't'): 'contribut',\n",
       " ('contribut', 'eĠ'): 'contributeĠ',\n",
       " ('i', 'mp'): 'imp',\n",
       " ('imp', 'ro'): 'impro',\n",
       " ('impro', 'v'): 'improv',\n",
       " ('improv', 'e'): 'improve',\n",
       " ('improve', 'dĠ'): 'improvedĠ',\n",
       " ('g', 'en'): 'gen',\n",
       " ('gen', 'er'): 'gener',\n",
       " ('gener', 'al'): 'general',\n",
       " ('general', 'i'): 'generali',\n",
       " ('generali', 'z'): 'generaliz',\n",
       " ('generaliz', 'ation'): 'generalization',\n",
       " ('generalization', ',Ġ'): 'generalization,Ġ',\n",
       " ('a', 'sĠ'): 'asĠ',\n",
       " ('i', 'tĠ'): 'itĠ',\n",
       " ('exp', 'o'): 'expo',\n",
       " ('expo', 'se'): 'expose',\n",
       " ('expose', 'sĠ'): 'exposesĠ',\n",
       " ('d', 'iv'): 'div',\n",
       " ('div', 'er'): 'diver',\n",
       " ('diver', 's'): 'divers',\n",
       " ('divers', 'eĠ'): 'diverseĠ',\n",
       " ('re', 'p'): 'rep',\n",
       " ('rep', 're'): 'repre',\n",
       " ('repre', 's'): 'repres',\n",
       " ('repres', 'en'): 'represen',\n",
       " ('represen', 't'): 'represent',\n",
       " ('represent', 'ation'): 'representation',\n",
       " ('representation', 'sĠ'): 'representationsĠ',\n",
       " ('an', 'dĠ'): 'andĠ',\n",
       " ('v', 'ar'): 'var',\n",
       " ('var', 'i'): 'vari',\n",
       " ('vari', 'ation'): 'variation',\n",
       " ('variation', 's.Ġ'): 'variations.Ġ'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_merges = {}\n",
    "# load merges\n",
    "with open(\"merges.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        pair, merge = line.split(\" -> \")\n",
    "        pair = tuple(pair.split())\n",
    "        new_merges[pair] = merge\n",
    "new_merges"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
